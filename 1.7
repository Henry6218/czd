# 1.7大模型推理系统基础知识总结

# 大模型推理系统的组成部分
# 1. 用户请求（应用、UI）
# 2. 处理用户请求（多个用户请求，对话框、API 等等）
# 3. 大模型、神经网络
# 4. 算子、参数、资源管理
# 5. 加速硬件
# 需在特定平台上，结合不同加速卡、操作系统进行针对性优化

# 大模型定义
# 具有大规模参数和复杂计算结构的机器学习模型，由深度人工神经网络构成

# 传统模型的局限性
# 传统模型使用已知数学公式（如多项式），参数未知但公式已知
# 目标是找到一组最优参数集合，使公式以最优方式拟合数据点
# 若找不到相应参数，则尽可能逼近数据
# 弊端：需要进行一些假设，若数学公式不符合实际，无法找到合适参数

# 人工神经网络
# 由大量神经元构成，每个神经元包含线性计算和非线性计算
# 线性计算改变输入信号的权重（放大或缩小）和偏移
# 非线性计算代表神经元是否激活

# 神经网络决策
# 参数：w 权重；b 偏移
# 简单决策公式：w0x0 + w1x1 + b = 0
# 复杂情况可引入两次判断（使用两个神经元）
# 无论多复杂的多边形，都可通过画多根直线拟合

# 万能近似定理
# 三层神经网络（一个输入层，一个隐藏层，一个输出层）
# 在理论上可以近似任意复杂（有限维度）的决策边界
# 若输入维度更高，增加 x 的数量；若输出种类更多，增加 y 的数量

# 例子：图像分类
# 每张图可看作长度 28 * 28 的向量
# 神经网络进行“画线操作”后输出，为数字图片分类

# 训练与推理
# 训练：通过大量已知数据调整模型参数，使其更准确地对新数据进行预测
# 步骤：定义损失函数，按减少损失的方向调整参数（梯度下降法），要有好的模型结构
# 推理：使用训练好的参数，对新的数据进行预测
# 三层神经网络有时难找到特征关系，或数字向量部分元素为空
# 需从高维数据抽象出特征，引导训练过程

# 深度神经网络优势
# 通过更多层次的解构，用较少参数捕捉更复杂的特征关系，提升参数效率
# 特殊结构如 CNN、RNN、Transformer，可引导模型用更少参数捕捉特定特征

# 大模型核心算子
# 矩阵乘：
# - 批量进行神经元的线性计算 y = xw^T + b
# - 大模型计算中总耗时最长的算子
# - 存储权重矩阵时要进行转置操作

# 大模型算子：激活函数
# 属于非线性计算，训练时需对函数求导才能进行梯度下降

# 大模型中的神经网络：多层感知器（MLP），也称为前馈神经网络（FFN）
# 性质：
# - 推理时参数固定，同样的输入意味着同样的输出
# - 多个输入向量之间不会互相影响，没有顺序之分
# 此方式无法实现类似 ChatGPT 的大语言模型，后续可用 Transformer 结构解决

# 大模型的规模
# 1B = 十亿（10^9）参数 * （数据类型大小）
# - fp16、bf16 是最常见的数据类型，更小的量化类型如 int8 成为趋势
# - 每个权重矩阵可能有上亿个参数
# - 一个模型可有几十甚至上百层神经网络
# - 神经网络的激活很稀疏，许多权重计算结果为 0，带来优化空间
